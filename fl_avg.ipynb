{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import torchvision\n",
    "import re\n",
    "import numpy\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = torch.nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = torch.nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return torch.nn.functional.cross_entropy(input, target)\n",
    "\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, model, dataloader, optimizer='adam', device='cpu', epochs=1, loss=Loss()):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        # self.loss = loss\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        if optimizer == 'adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        else:\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters())\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, (data, label) in enumerate(self.dataloader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data.to(self.device))\n",
    "                loss = self.loss(output, label.to(self.device))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, self.epochs, i+1, len(self.dataloader), loss.item()))\n",
    "        return self.model.state_dict()\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, model, client_params):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.client_params = client_params\n",
    "        self.n_client = len(self.client_params)\n",
    "\n",
    "        self.clients = list(client_params.keys())\n",
    "        self.server_params = self.client_params[self.clients[0]]\n",
    "        for key in self.server_params:\n",
    "            self.server_params[key] = self.server_params[key].div(self.n_client)\n",
    "\n",
    "    def fed_avg(self):\n",
    "        for client in self.clients:\n",
    "            for key in self.server_params:\n",
    "                self.server_params[key] = self.server_params[key].add(self.client_params[client][key].div(self.n_client))\n",
    "        return self.server_params\n",
    "\n",
    "\n",
    "class DealDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, idx):\n",
    "        self.dataset = dataset\n",
    "        self.idx = idx\n",
    "        self.len = len(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.dataset[self.idx[index]]\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateSplit(dataset, mode='iid', n_dataset=1, n_data_each_set=1):\n",
    "    if mode == 'iid':\n",
    "        labels_list = dataset.targets.tolist()\n",
    "        all_labels = set(labels_list)\n",
    "        idx_label = dict()\n",
    "        for label in all_labels:\n",
    "            idx_label[label] = list([\n",
    "                idx for idx, _ in enumerate(labels_list) if labels_list[idx] == label])\n",
    "        dataset_splited = dict()\n",
    "        for i in range(n_dataset):\n",
    "            dataset_splited[i] = list()\n",
    "            for label in all_labels:\n",
    "                choiced_idx = numpy.random.choice(idx_label[label], n_data_each_set, replace=False)\n",
    "                dataset_splited[i] += list(choiced_idx)\n",
    "        return dataset_splited\n",
    "    elif mode == 'non-iid':\n",
    "        print('TO DO.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = LeNet5()\n",
    "criterion = Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "n_client = 10\n",
    "n_data = 3200\n",
    "idx_splited = DateSplit(dataset=train_dataset,\n",
    "                        n_dataset=n_client,\n",
    "                        n_data_each_set=n_data)\n",
    "\n",
    "choice_client = 10\n",
    "conmunication_rounds = 2\n",
    "\n",
    "server_params = copy.deepcopy(model).state_dict()\n",
    "for i in range(conmunication_rounds):\n",
    "    client_params = dict()\n",
    "    for client in list(numpy.random.choice(range(n_client), choice_client, replace=False)):\n",
    "        client_model = copy.deepcopy(model)\n",
    "        client_model.load_state_dict(server_params)\n",
    "        client_params[client] = Client(model=client_model,\n",
    "                            dataloader = DataLoader(\n",
    "                                DealDataset(train_dataset,\n",
    "                                            idx_splited[client]),\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False\n",
    "                                            ),\n",
    "                                optimizer='adam',\n",
    "                                device=device).train()\n",
    "    server_params = Server(model=model, client_params=client_params).fed_avg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model = copy.deepcopy(model)\n",
    "server_model.load_state_dict(server_params)\n",
    "server_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = server_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
