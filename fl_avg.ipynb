{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import torchvision\n",
    "import re\n",
    "import numpy\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=input_channels, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = torch.nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = torch.nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return torch.nn.functional.cross_entropy(input, target)\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, model, client_params):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.client_params = client_params\n",
    "        self.n_client = len(self.client_params)\n",
    "\n",
    "        self.server_params = self.client_params[0]\n",
    "        for key in self.server_params:\n",
    "            self.server_params[key] = self.server_params[key].div(\n",
    "                self.n_client)\n",
    "\n",
    "    def fed_avg(self):\n",
    "        for client in range(self.n_client):\n",
    "            for key in self.server_params:\n",
    "                deal_param = self.client_params[client][key].div(self.n_client)\n",
    "                self.server_params[key] = self.server_params[key].add(deal_param)\n",
    "        return self.server_params\n",
    "\n",
    "\n",
    "class DealDataset(Dataset):\n",
    "    def __init__(self, dataset, idx):\n",
    "        self.dataset = dataset\n",
    "        self.idx = idx\n",
    "        self.len = len(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.dataset[self.idx[index]]\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_split(dataset, mode='iid', n_dataset=1, n_data_each_set=1):\n",
    "    labels_list = dataset.targets.tolist()\n",
    "    all_labels = set(labels_list)\n",
    "    idx_label = dict()\n",
    "    for label in all_labels:\n",
    "        idx_label[label] = list()\n",
    "        for idx, label_in_list in enumerate(labels_list):\n",
    "            if label_in_list == label:\n",
    "                idx_label[label] += [idx]\n",
    "\n",
    "    if mode == 'iid':\n",
    "        n_each_set = dict()\n",
    "        for label in all_labels:\n",
    "            n_each_set[label] = int(\n",
    "                len(idx_label[label]) / len(labels_list) * n_data_each_set / n_dataset)\n",
    "            print(label, n_each_set[label], end='|')\n",
    "        print('\\n')\n",
    "        dataset_splited = dict()\n",
    "        left_idx_label = idx_label\n",
    "        for i in range(n_dataset):\n",
    "            dataset_splited[i] = list()\n",
    "            for label in all_labels:\n",
    "                choiced_idx = numpy.random.choice(\n",
    "                    left_idx_label[label],\n",
    "                    n_each_set[label],\n",
    "                    replace=False)\n",
    "                dataset_splited[i] += list(choiced_idx)\n",
    "                left_idx_label[i] = list(\n",
    "                    set(left_idx_label[label]) - set(dataset_splited[i]))\n",
    "                print(i, label, len(dataset_splited[i]), n_each_set[label], len(left_idx_label[i]))\n",
    "        return dataset_splited\n",
    "    elif mode == 'non-iid':\n",
    "        print('TO DO.')\n",
    "\n",
    "\n",
    "def train_model(model, dataset, device='cpu', epochs=1):\n",
    "    trained_model = copy.deepcopy(model).to(device)\n",
    "    trained_model.train()\n",
    "    train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(trained_model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            output = trained_model(data.to(device))\n",
    "            loss = criterion(output, label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #     if (i+1) % 100 == 0:\n",
    "        #         print('\\r', end='')\n",
    "        #         print(\n",
    "        #             f'step [{i+1}/{len(train_dataloader)}], loss: {loss.item():.4f}', end='')\n",
    "        # print(f'\\nepoch {epoch+1}/{epochs} down.')\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def eval_model(model, dataset):\n",
    "    server_model = copy.deepcopy(model)\n",
    "    server_model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        for images, labels in data_loader:\n",
    "            outputs = server_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        # print('Test Accuracy: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0 98|1 112|2 99|3 102|4 97|5 90|6 98|7 104|8 97|9 99|\n",
      "\n",
      "0 0 98 98 5825\n",
      "0 1 210 112 6630\n",
      "0 2 309 99 5859\n",
      "0 3 411 102 6029\n",
      "0 4 508 97 5745\n",
      "0 5 598 90 5331\n",
      "0 6 696 98 5820\n",
      "0 7 800 104 6161\n",
      "0 8 897 97 5754\n",
      "0 9 996 99 5850\n",
      "1 0 98 98 5752\n",
      "1 1 210 112 5640\n",
      "1 2 309 99 5859\n",
      "1 3 411 102 6029\n",
      "1 4 508 97 5745\n",
      "1 5 598 90 5331\n",
      "1 6 696 98 5820\n",
      "1 7 800 104 6161\n",
      "1 8 897 97 5754\n",
      "1 9 996 99 5642\n",
      "2 0 98 98 5752\n",
      "2 1 210 112 5442\n",
      "2 2 309 99 5343\n",
      "2 3 411 102 6029\n",
      "2 4 508 97 5745\n",
      "2 5 598 90 5331\n",
      "2 6 696 98 5820\n",
      "2 7 800 104 6161\n",
      "2 8 897 97 5754\n",
      "2 9 996 99 5547\n",
      "3 0 98 98 5752\n",
      "3 1 210 112 5437\n",
      "3 2 309 99 5254\n",
      "3 3 411 102 5152\n",
      "3 4 508 97 5745\n",
      "3 5 598 90 5331\n",
      "3 6 696 98 5820\n",
      "3 7 800 104 6161\n",
      "3 8 897 97 5754\n",
      "3 9 996 99 5451\n",
      "4 0 98 98 5752\n",
      "4 1 210 112 5438\n",
      "4 2 309 99 5249\n",
      "4 3 411 102 5071\n",
      "4 4 508 97 4974\n",
      "4 5 598 90 5331\n",
      "4 6 696 98 5820\n",
      "4 7 800 104 6161\n",
      "4 8 897 97 5754\n",
      "4 9 996 99 5358\n",
      "5 0 98 98 5752\n",
      "5 1 210 112 5443\n",
      "5 2 309 99 5257\n",
      "5 3 411 102 5088\n",
      "5 4 508 97 4913\n",
      "5 5 598 90 4823\n",
      "5 6 696 98 5820\n",
      "5 7 800 104 6161\n",
      "5 8 897 97 5754\n",
      "5 9 996 99 5278\n",
      "6 0 98 98 5752\n",
      "6 1 210 112 5438\n",
      "6 2 309 99 5258\n",
      "6 3 411 102 5074\n",
      "6 4 508 97 4913\n",
      "6 5 598 90 4768\n",
      "6 6 696 98 4670\n",
      "6 7 800 104 6161\n",
      "6 8 897 97 5754\n",
      "6 9 996 99 5192\n",
      "7 0 98 98 5752\n",
      "7 1 210 112 5441\n",
      "7 2 309 99 5254\n",
      "7 3 411 102 5068\n",
      "7 4 508 97 4906\n",
      "7 5 598 90 4752\n",
      "7 6 696 98 4601\n",
      "7 7 800 104 4497\n",
      "7 8 897 97 5754\n",
      "7 9 996 99 5096\n",
      "8 0 98 98 5752\n",
      "8 1 210 112 5440\n",
      "8 2 309 99 5261\n",
      "8 3 411 102 5075\n",
      "8 4 508 97 4910\n",
      "8 5 598 90 4756\n",
      "8 6 696 98 4601\n",
      "8 7 800 104 4424\n",
      "8 8 897 97 4327\n",
      "8 9 996 99 5007\n",
      "9 0 98 98 5752\n",
      "9 1 210 112 5439\n",
      "9 2 309 99 5251\n",
      "9 3 411 102 5081\n",
      "9 4 508 97 4905\n",
      "9 5 598 90 4757\n",
      "9 6 696 98 4598\n",
      "9 7 800 104 4431\n",
      "9 8 897 97 4278\n",
      "9 9 996 99 4179\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "n_total_client = 10\n",
    "n_data = 10000\n",
    "communication_round = 1\n",
    "epochs = 1\n",
    "n_client = 3\n",
    "\n",
    "model = LeNet5(input_channels=1)\n",
    "idx_splited = idx_split(dataset=train_dataset,\n",
    "                        n_dataset=n_total_client,\n",
    "                        n_data_each_set=n_data)\n",
    "dataset_client = dict()\n",
    "for i in range(n_total_client):\n",
    "    dataset_client[i] = DealDataset(train_dataset, idx_splited[i])\n",
    "\n",
    "server_model = model\n",
    "for i in range(communication_round):\n",
    "    client = dict()\n",
    "    choicen_client = numpy.random.choice(\n",
    "        range(n_total_client), n_client, replace=False)\n",
    "    for j, k in enumerate(choicen_client):\n",
    "        client[j] = train_model(\n",
    "            model=server_model,\n",
    "            dataset=DealDataset(train_dataset, idx_splited[k]),\n",
    "            device=device,\n",
    "            epochs=epochs).state_dict()\n",
    "    server_model = Server(model=model, client_params=client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
